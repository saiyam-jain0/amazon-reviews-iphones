{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAg48Z2D-2PO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = '/content/drive/My Drive/reviews of all models'\n",
        "\n",
        "file_pattern = os.path.join(folder_path, '*.csv')\n",
        "all_csv_files = glob.glob(file_pattern)\n",
        "\n",
        "all_dfs_list = []\n",
        "print(f\"--- Found {len(all_csv_files)} starting to process... ---\")\n",
        "\n",
        "for filename in all_csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "        #(e.g., 'iphone_12_pro.csv') to readable model name ('iphone 12 pro')\n",
        "        model_name = os.path.basename(filename).replace('.csv', '').replace('_', ' ')\n",
        "        df['model'] = model_name\n",
        "        all_dfs_list.append(df)\n",
        "        print(f\"Processed {os.path.basename(filename)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred with {os.path.basename(filename)}: {e}\")\n",
        "\n",
        "if all_dfs_list:\n",
        "    # Concatenate all DataFrames into one\n",
        "    merged_df = pd.concat(all_dfs_list, ignore_index=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"--- All files have been successfully merged! ---\")\n",
        "\n",
        "    # Show summary of merged dataset\n",
        "    print(f\"\\nFinal dataset contains {merged_df.shape[0]} reviews from {len(all_dfs_list)} files.\")\n",
        "    print(\"First 5 rows:\")\n",
        "    print(merged_df.head())\n",
        "\n",
        "    # Save merged data to a new CSV\n",
        "    output_filename = 'merged_reviews.csv'\n",
        "    merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(f\"\\nMerged data saved to '{output_filename}' in your Colab session.\")\n",
        "    print(\"You can now download this file from the file pane on the left.\")\n",
        "else:\n",
        "    print(\"\\nNo CSV files were found or processed. Please check the folder path and ensure it contains CSV files.\")\n"
      ],
      "metadata": {
        "id": "l5bq5euk-9DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv( '/content/merged_reviews.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HQRTzE1j_EcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "XH5eSWFs_IBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "iS_P7FDB_J8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "6pVeOiO0_Nw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['model'].value_counts()"
      ],
      "metadata": {
        "id": "G3jdXNuy_PHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['input']"
      ],
      "metadata": {
        "id": "jAI0Uvus_QPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['isAmazonVine']"
      ],
      "metadata": {
        "id": "0A-dcYHH_SeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['position']"
      ],
      "metadata": {
        "id": "yqumrdMG_Ue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['reviewReaction']"
      ],
      "metadata": {
        "id": "0xiV9iab_W0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df[[\n",
        "    'model',\n",
        "    'ratingScore',\n",
        "    'reviewTitle',\n",
        "    'reviewDescription',\n",
        "    'date',\n",
        "]].copy()\n",
        "print(new_df.head())"
      ],
      "metadata": {
        "id": "z_hcQ7B-_YwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "hsTRNUN8_aYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "H3pX0kE5_dCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['date'] = pd.to_datetime(new_df['date'])"
      ],
      "metadata": {
        "id": "Kdn8vZDA_e41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "_fHKrGwH_g0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['reviewDescription'] = new_df['reviewDescription'].fillna('  ')"
      ],
      "metadata": {
        "id": "Xg3o3u-r_i60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.info()"
      ],
      "metadata": {
        "id": "MUYuBpoe_lHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langdetect googletrans==4.0.0-rc1\n",
        "\n",
        "\n",
        "from langdetect import detect, LangDetectException\n",
        "from googletrans import Translator\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# --- Create the combined text column ---\n",
        "new_df['full_review_text'] = new_df['reviewTitle'].astype(str) + \". \" + new_df['reviewDescription'].astype(str)\n",
        "\n",
        "# --- Define the language detection function ---\n",
        "def is_spanish(text):\n",
        "    try:\n",
        "        return detect(text) == 'es'\n",
        "    except LangDetectException:\n",
        "        return False\n",
        "\n",
        "# --- Identify Spanish reviews ---\n",
        "print(\"Detecting language for each review...\")\n",
        "tqdm.pandas(desc=\"Language Detection\")\n",
        "is_spanish_series = new_df['full_review_text'].progress_apply(is_spanish)\n",
        "spanish_indices = is_spanish_series[is_spanish_series == True].index\n",
        "print(f\" Found {len(spanish_indices)} Spanish reviews to translate.\")\n",
        "\n",
        "# --- Translate and overwrite in the same column ---\n",
        "translator = Translator()\n",
        "\n",
        "# Loop only through the reviews identified as Spanish\n",
        "for i in tqdm(spanish_indices, desc=\"Translating Spanish Reviews\"):\n",
        "    try:\n",
        "        original_text = new_df.loc[i, 'full_review_text']\n",
        "        translated_text = translator.translate(original_text, src='es', dest='en').text\n",
        "        # Overwrite the original text with the translation\n",
        "        new_df.loc[i, 'full_review_text'] = translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Could not translate row {i}: {e}\")\n",
        "\n",
        "print(\"\\n In-place translation complete.\")\n",
        "print(\"\\n--- DataFrame with Updated 'full_review_text' Column ---\")\n",
        "print(new_df[['full_review_text']].head())"
      ],
      "metadata": {
        "id": "fnH7sPxmMjGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from tqdm import tqdm #this is just to track progress\n",
        "tqdm.pandas()\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
      ],
      "metadata": {
        "id": "AYj3NcoB_m9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['full_review_text']"
      ],
      "metadata": {
        "id": "9Sw8HfMuAhZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(text):\n",
        "    try:\n",
        "        truncated_text = ' '.join(str(text).split()[:510])\n",
        "        result = sentiment_pipeline(truncated_text)[0]\n",
        "        if result['label'] == 'Positive':\n",
        "            return 1\n",
        "        elif result['label'] == 'Neutral':\n",
        "            return 0\n",
        "        else:\n",
        "            return -1\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "new_df['sentiment_score'] = new_df['full_review_text'].progress_apply(get_sentiment)"
      ],
      "metadata": {
        "id": "q_BnCn5sAqpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_sentiment_count = new_df[new_df['sentiment_score'] == -1].shape[0]"
      ],
      "metadata": {
        "id": "V2ECEtyhDGRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(negative_sentiment_count)"
      ],
      "metadata": {
        "id": "cwYeuxonDJRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n",
        "!pip install gensim nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re"
      ],
      "metadata": {
        "id": "e20TskyKDI6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "98RUbdCuDI0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding some custom stop words that are common in phone reviews but not very informative\n",
        "custom_stop_words = ['phone', 'iphone', 'apple', 'amazon', 'product', 'get', 'one',\n",
        "                     'would', 'like', 'bought', 'buy', 'also', 'issue', 'problem']\n",
        "\n",
        "stop_words.update(custom_stop_words)"
      ],
      "metadata": {
        "id": "mME9JfLqDIop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "Rspy4EQjDIMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.columns"
      ],
      "metadata": {
        "id": "JI7aUwUwDgPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [\n",
        "        lemmatizer.lemmatize(word)\n",
        "        for word in tokens\n",
        "        if word not in stop_words and len(word) > 2\n",
        "    ]\n",
        "    return processed_tokens\n",
        "\n",
        "new_df['processed_text'] = new_df['full_review_text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Text preprocessing complete.\")\n",
        "print(new_df[['full_review_text', 'processed_text']].head())"
      ],
      "metadata": {
        "id": "ZHdtSD4xDf7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['processed_text']"
      ],
      "metadata": {
        "id": "JWxkoRqBDf0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "tokenized_reviews = new_df['processed_text'].tolist()\n",
        "\n",
        "phrases = Phrases(tokenized_reviews, min_count=5, threshold=10)\n",
        "bigram_phraser = Phraser(phrases)\n",
        "\n",
        "new_df.loc[:, 'processed_text_bigrams'] = new_df['processed_text'].apply(lambda tokens: bigram_phraser[tokens])\n",
        "print(\"--- Example of bigram creation ---\")\n",
        "print(new_df[['processed_text', 'processed_text_bigrams']].head())\n"
      ],
      "metadata": {
        "id": "Z-OfbgZaDfur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "processed_docs = new_df['processed_text_bigrams'].tolist()\n",
        "\n",
        "dictionary = corpora.Dictionary(processed_docs)\n",
        "\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "print(f\"Created a dictionary with {len(dictionary)} unique words.\")\n",
        "print(f\"Created a corpus with {len(corpus)} documents.\")"
      ],
      "metadata": {
        "id": "og_e3MLzDfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def find_optimal_topics(dictionary, corpus, texts, limit=16):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "\n",
        "    for num_topics in tqdm(range(2, limit), desc=\"Finding Optimal Topics\"):\n",
        "        model = LdaMulticore(\n",
        "            corpus=corpus,\n",
        "            id2word=dictionary,\n",
        "            num_topics=num_topics,\n",
        "            random_state=100,\n",
        "            chunksize=100,\n",
        "            passes=10,\n",
        "            per_word_topics=True\n",
        "        )\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(\n",
        "            model=model,\n",
        "            texts=texts,\n",
        "            dictionary=dictionary,\n",
        "            coherence='c_v'\n",
        "        )\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n",
        "\n",
        "model_list, coherence_values = find_optimal_topics(\n",
        "    dictionary=dictionary,\n",
        "    corpus=corpus,\n",
        "    texts=new_df['processed_text_bigrams'].tolist(),\n",
        "    limit=16\n",
        ")\n",
        "\n",
        "x = range(2, 16)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Number of Topics\")\n",
        "plt.ylabel(\"Coherence Score\")\n",
        "plt.title(\"Finding the Optimal Number of Topics\")\n",
        "plt.xticks(x)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zIYrWLw_Du01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import CoherenceModel\n",
        "from pprint import pprint\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "lda_model_4_topics = gensim.models.LdaMulticore(\n",
        "    corpus=corpus, id2word=dictionary, num_topics=4,\n",
        "    random_state=100, chunksize=100, passes=20\n",
        ")\n",
        "\n",
        "lda_model_6_topics = gensim.models.LdaMulticore(\n",
        "    corpus=corpus, id2word=dictionary, num_topics=6,\n",
        "    random_state=100, chunksize=100, passes=20\n",
        ")\n",
        "\n",
        "print(\"Models trained successfully.\")\n",
        "\n",
        "coherence_4 = CoherenceModel(\n",
        "    model=lda_model_4_topics,\n",
        "    texts=new_df['processed_text_bigrams'],\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "coherence_6 = CoherenceModel(\n",
        "    model=lda_model_6_topics,\n",
        "    texts=new_df['processed_text_bigrams'],\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "print(\"\\nModel Coherence Scores\")\n",
        "print(f\"4 Topics: {coherence_4:.4f}\")\n",
        "print(f\"6 Topics: {coherence_6:.4f}\")\n",
        "\n",
        "def assign_topics(lda_model, corpus):\n",
        "    return [max(prob_dist, key=lambda item: item[1])[0]\n",
        "            for prob_dist in tqdm(lda_model[corpus], desc=f\"Assigning {lda_model.num_topics} Topics\")]\n",
        "\n",
        "new_df['topic_4'] = assign_topics(lda_model_4_topics, corpus)\n",
        "new_df['topic_6'] = assign_topics(lda_model_6_topics, corpus)\n",
        "\n",
        "print(\"\\nTopic labels assigned.\")\n",
        "\n",
        "print(\"\\nTopics from 4-Topic Model\")\n",
        "pprint(lda_model_4_topics.print_topics())\n",
        "\n",
        "print(\"\\nTopics from 6-Topic Model\")\n",
        "pprint(lda_model_6_topics.print_topics())\n",
        "\n",
        "print(\"\\nSample with Topic Labels\")\n",
        "print(new_df[['full_review_text', 'topic_4', 'topic_6']].head())"
      ],
      "metadata": {
        "id": "5dzg_j7SDuuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import CoherenceModel\n",
        "from pprint import pprint\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Train models\n",
        "lda_model_2_topics = gensim.models.LdaMulticore(\n",
        "    corpus=corpus, id2word=dictionary, num_topics=2,\n",
        "    random_state=100, chunksize=100, passes=20\n",
        ")\n",
        "\n",
        "lda_model_3_topics = gensim.models.LdaMulticore(\n",
        "    corpus=corpus, id2word=dictionary, num_topics=3,\n",
        "    random_state=100, chunksize=100, passes=20\n",
        ")\n",
        "\n",
        "lda_model_5_topics = gensim.models.LdaMulticore(\n",
        "    corpus=corpus, id2word=dictionary, num_topics=5,\n",
        "    random_state=100, chunksize=100, passes=20\n",
        ")\n",
        "\n",
        "print(\"Models trained successfully.\")\n",
        "\n",
        "# Coherence scores\n",
        "coherence_2 = CoherenceModel(\n",
        "    model=lda_model_2_topics,\n",
        "    texts=new_df['processed_text_bigrams'],\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "coherence_3 = CoherenceModel(\n",
        "    model=lda_model_3_topics,\n",
        "    texts=new_df['processed_text_bigrams'],\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "coherence_5 = CoherenceModel(\n",
        "    model=lda_model_5_topics,\n",
        "    texts=new_df['processed_text_bigrams'],\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "print(\"\\nModel Coherence Scores\")\n",
        "print(f\"2 Topics: {coherence_2:.4f}\")\n",
        "print(f\"3 Topics: {coherence_3:.4f}\")\n",
        "print(f\"5 Topics: {coherence_5:.4f}\")\n",
        "\n",
        "def assign_topics(lda_model, corpus):\n",
        "    return [max(prob_dist, key=lambda item: item[1])[0]\n",
        "            for prob_dist in tqdm(lda_model[corpus], desc=f\"Assigning {lda_model.num_topics} Topics\")]\n",
        "\n",
        "# Assign topic labels\n",
        "new_df['topic_2'] = assign_topics(lda_model_2_topics, corpus)\n",
        "new_df['topic_3'] = assign_topics(lda_model_3_topics, corpus)\n",
        "new_df['topic_5'] = assign_topics(lda_model_5_topics, corpus)\n",
        "\n",
        "print(\"\\nTopic labels assigned.\")\n",
        "\n",
        "# Output topic summaries\n",
        "print(\"\\nTopics from 2-Topic Model\")\n",
        "pprint(lda_model_2_topics.print_topics())\n",
        "\n",
        "print(\"\\nTopics from 3-Topic Model\")\n",
        "pprint(lda_model_3_topics.print_topics())\n",
        "\n",
        "print(\"\\nTopics from 5-Topic Model\")\n",
        "pprint(lda_model_5_topics.print_topics())\n",
        "\n",
        "print(\"\\nSample with Topic Labels\")\n",
        "print(new_df[['full_review_text', 'topic_2', 'topic_3', 'topic_5']].head())"
      ],
      "metadata": {
        "id": "0rG8rPNCnEPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_topic_map = {\n",
        "    0: 'Seller & Carrier Unlockability',\n",
        "    1: 'Phone Functionality & Defects',\n",
        "    2: 'Screen & Cosmetic Condition',\n",
        "    3: 'Battery Life & Charging'\n",
        "}\n",
        "\n",
        "new_df['final_topic'] = new_df['topic_4'].map(final_topic_map)\n",
        "\n",
        "print(\"--- DataFrame with Final, Descriptive Topic Labels ---\")\n",
        "print(new_df[['full_review_text', 'final_topic']].head(20))"
      ],
      "metadata": {
        "id": "ubUCLO5prUjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_topic_distribution = new_df['final_topic'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\n--- Final Distribution of Complaint Topics ---\")\n",
        "print(final_topic_distribution)"
      ],
      "metadata": {
        "id": "T3jtfrbVukyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "crNxOET-u9h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x=final_topic_distribution.values, y=final_topic_distribution.index, palette='viridis')\n",
        "\n",
        "plt.title('Main Complaint Topics for Renewed iPhones', fontsize=16)\n",
        "plt.xlabel('Percentage of Reviews (%)', fontsize=12)\n",
        "plt.ylabel('Complaint Topic', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ORzer6vrwHQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_df.columns.tolist())"
      ],
      "metadata": {
        "id": "RiJ6LtzOxiZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud --quiet\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group by final topic\n",
        "topics = new_df['final_topic'].unique()\n",
        "\n",
        "for topic in topics:\n",
        "    text = ' '.join(new_df[new_df['final_topic'] == topic]['full_review_text'].dropna().astype(str))\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"WordCloud for Topic: {topic}\", fontsize=16)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1TZhG0t6wQMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = new_df['final_topic'].unique()\n",
        "\n",
        "for topic in topics:\n",
        "    text = ' '.join(new_df[new_df['final_topic'] == topic]['processed_text'].dropna().astype(str))\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"WordCloud for Topic: {topic}\", fontsize=16)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2oEGd0iVwP-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'date' is datetime\n",
        "new_df['date'] = pd.to_datetime(new_df['date'], errors='coerce')\n",
        "\n",
        "# Drop null dates\n",
        "timeline_df = new_df.dropna(subset=['date'])\n",
        "\n",
        "# Plot number of reviews per topic over time\n",
        "plt.figure(figsize=(14, 7))\n",
        "for topic in new_df['final_topic'].unique():\n",
        "    timeline_df[timeline_df['final_topic'] == topic].resample('M', on='date').size().plot(label=topic)\n",
        "\n",
        "plt.title(\"Topic Trend Over Time\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-swyFRDRyj-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=new_df, x='final_topic', y='ratingScore')\n",
        "plt.title(\"Review Ratings per Topic\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eToYApNny3Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.columns"
      ],
      "metadata": {
        "id": "LFDxwUpiy-Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "qF8maHrn0IFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_non_negative = (new_df['sentiment_score'] != -1).sum()\n",
        "print(f\"Number of entries where sentiment_score is not -1: {count_non_negative}\")"
      ],
      "metadata": {
        "id": "TeAYNSSV06UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_counts = new_df['sentiment_score'].value_counts().sort_index()\n",
        "\n",
        "print(\"Sentiment Summary\")\n",
        "print(f\"Negative (-1): {sentiment_counts.get(-1, 0)}\")\n",
        "print(f\"Neutral (0):   {sentiment_counts.get(0, 0)}\")\n",
        "print(f\"Positive (1):  {sentiment_counts.get(1, 0)}\")\n"
      ],
      "metadata": {
        "id": "0IPLbnfQ4pK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_for_dashboard = [\n",
        "    'model',\n",
        "    'ratingScore',\n",
        "    'date',\n",
        "    'full_review_text',\n",
        "    'sentiment_score',\n",
        "    'final_topic'\n",
        "]"
      ],
      "metadata": {
        "id": "qnXVsYAs64S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dashboard_df = new_df[columns_for_dashboard].copy()\n",
        "\n",
        "dashboard_df.to_csv('dashboard_ready_data.csv', index=False)\n",
        "print(\"done'dashboard_ready_data.csv'\")"
      ],
      "metadata": {
        "id": "-Q-Zb-JN64B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_df.to_excel(\"dashboard_ready_data.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "Myzqyo7u1s3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}